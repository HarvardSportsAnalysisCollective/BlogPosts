{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit and Test Decay-K ELO Model Against 538's ELO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in Data\n",
    "data538 = pd.read_csv('nba_elo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Fit ELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_post_elo(home_team, home_team_elo, away_team, away_team_elo, mov, decay):\n",
    "    \n",
    "    home_post_elo = get_k(mov, home_team_elo, away_team_elo, decay)*(int(mov>0) - get_win_prob(home_team_elo, away_team_elo)) + home_team_elo\n",
    "    away_post_elo = away_team_elo + (home_team_elo - home_post_elo)\n",
    "    \n",
    "    return home_post_elo, away_post_elo\n",
    "    \n",
    "def get_win_prob(home_team_elo, away_team_elo):\n",
    "    home_team_elo += 100\n",
    "    return 1.0/(1.0+(10.0**((away_team_elo-home_team_elo)/400)))\n",
    "\n",
    "def get_k(mov, team_elo, opp_elo, decay):\n",
    "    \n",
    "    if mov > 0: elo_dif = team_elo-opp_elo\n",
    "    else: elo_dif = opp_elo-team_elo\n",
    "    \n",
    "    K = 20.0*((np.abs(mov)+3.0)**.8)\n",
    "    K = K/(7.5 + .006*elo_dif)\n",
    "    return K*decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Details:\n",
    " - Trained on 2010 - 2014 seasons\n",
    " - Validated on 2015 - 2016 seasons\n",
    " - Tested/Comppared to 538's Model on 2017 - 2018 seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get Just Seasons 2010 and on\n",
    "games = data538[data538['season'] >= 2010]\n",
    "games = games[games['season'] < 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters to Tune\n",
    "season_start_epsilons = [.8, .9, .95, .98, 1.0, 1.02, 1.05, 1.1, 1.2]\n",
    "epsilon_decays = [.6, .7, .8, .9, .95, .98, 1.0, 1.02, 1.05, 1.1, 1.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ejohn\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:84: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\ejohn\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: overflow encountered in double_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Accuracy:  -1558.55904808\n",
      "Best start_epsilon:  1.2\n",
      "Best epsilon_decay:  0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ejohn\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Get Decay ELOs\n",
    "\n",
    "VALIDATE_YEAR = 2015\n",
    "TEST_YEAR = 2017\n",
    "\n",
    "val_results_dict_list = []\n",
    "test_results_dict_list = []\n",
    "\n",
    "# For Each Combination of start_epsilon and epsilon_decay\n",
    "for season_start_epsilon in season_start_epsilons:\n",
    "    for epsilon_decay in epsilon_decays:\n",
    "    \n",
    "        epsilon = season_start_epsilon\n",
    "\n",
    "        elo_dict = {}\n",
    "\n",
    "        val_dict_list = []\n",
    "        test_dict_list = []\n",
    "\n",
    "        # For Each Game\n",
    "        for i in range(games.shape[0]):\n",
    "\n",
    "            # Get Game Info\n",
    "            row = games.iloc[i]\n",
    "            team = row.team1\n",
    "            opp = row.team2\n",
    "            mov = row.score1 - row.score2\n",
    "\n",
    "            # Seasonal ELO Adjustment for Every Team\n",
    "            if i > 0 and row.season != games.iloc[i-1].season:\n",
    "                for k in elo_dict.keys():\n",
    "                    elo_dict[k] = .75*elo_dict[k] + .25*1505\n",
    "                    \n",
    "                # Reset Epsilon\n",
    "                epsilon = season_start_epsilon\n",
    "\n",
    "            # If team's first game, use 538's elo to start\n",
    "            if team not in elo_dict.keys():\n",
    "                elo_dict[team] = row['elo1_pre']\n",
    "            if opp not in elo_dict.keys():\n",
    "                elo_dict[opp] = row['elo2_pre']\n",
    "\n",
    "            # Get Pre-Game ELO Estimates\n",
    "            team_pre = elo_dict[team]\n",
    "            opp_pre = elo_dict[opp]\n",
    "\n",
    "            # Adjust Epsilon Every 100 Games\n",
    "            if i % 100 == 0:\n",
    "                epsilon *= epsilon_decay\n",
    "\n",
    "            # Update ELOs based on game results    \n",
    "            elo_dict[team], elo_dict[opp] = get_post_elo(team, team_pre, opp, opp_pre, mov, epsilon)\n",
    "\n",
    "            # Model Validation\n",
    "            if row.season >= VALIDATE_YEAR and row.season < TEST_YEAR:\n",
    "                \n",
    "                # Build DataFrame with Post-Game ELOs\n",
    "                team_post = elo_dict[team]\n",
    "                opp_post = elo_dict[opp]\n",
    "                val_dict_list.append({'team1': team, 'team2': opp, 'team1_pre': team_pre, 'team2_pre': opp_pre, 'team1_post': team_post, 'team2_post': opp_post, 'MOV': mov})\n",
    "            \n",
    "        ########################\n",
    "        # Validation DataFrame\n",
    "        ########################\n",
    "        '''Choose the best model based on the validation set'''\n",
    "        \n",
    "        val_df = pd.DataFrame(val_dict_list)\n",
    "        \n",
    "        preds = []\n",
    "        losses = []\n",
    "        outcomes = []\n",
    "        \n",
    "        # For Each Game in Validation Set\n",
    "        for i in range(val_df.shape[0]):\n",
    "\n",
    "            # Get Game Info\n",
    "            row = val_df.iloc[i]\n",
    "            mov = row.MOV \n",
    "            team_elo = row['team1_pre']\n",
    "            opp_elo = row['team2_pre']\n",
    "\n",
    "            # Get Predictions, Loss, and Results\n",
    "            preds.append(get_win_prob(team_elo, opp_elo) > .5)\n",
    "            losses.append(np.log(get_win_prob(team_elo, opp_elo) if mov > 0 else 1 - get_win_prob(team_elo, opp_elo)))\n",
    "            outcomes.append(mov > 0)\n",
    "\n",
    "        # True if Success, Otherwise False\n",
    "        #success_list = [preds[j] == outcomes[j] for j in range(len(preds))]\n",
    "        \n",
    "        # Record Overall Loss\n",
    "        \n",
    "        \n",
    "        # Make DataFrame of Validation Results\n",
    "        #val_results_dict_list.append({'accuracy': np.mean(success_list), 'season_start_ep': season_start_epsilon, 'epsilon_decay': epsilon_decay})\n",
    "        \n",
    "        # Make DataFrame of Validation Results w/ Loss as accuracy\n",
    "        val_results_dict_list.append({'accuracy': np.sum(losses), 'season_start_ep': season_start_epsilon, 'epsilon_decay': epsilon_decay})\n",
    "        \n",
    "val_results_df = pd.DataFrame(val_results_dict_list)\n",
    "\n",
    "print('Best Validation Accuracy: ', np.max(val_results_df['accuracy']))\n",
    "print('Best start_epsilon: ', val_results_df.loc[np.argmax(val_results_df['accuracy'])].season_start_ep)\n",
    "print('Best epsilon_decay: ', val_results_df.loc[np.argmax(val_results_df['accuracy'])].epsilon_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ejohn\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of Chosen Model (on 2017 and 2018):  -1633.53216217\n",
      "Loss of Chosen Model (on 2017 and 2018):  0.65623807707\n"
     ]
    }
   ],
   "source": [
    "# Re-Fit Model w/ Best Validation Results\n",
    "VALIDATE_YEAR = 2015\n",
    "TEST_YEAR = 2017\n",
    "\n",
    "test_results_dict_list = []\n",
    "\n",
    "# Get Hyperparameters from Validated Model\n",
    "season_start_epsilon = val_results_df.loc[np.argmax(val_results_df['accuracy'])].season_start_ep\n",
    "epsilon_decay = val_results_df.loc[np.argmax(val_results_df['accuracy'])].epsilon_decay\n",
    "\n",
    "######################\n",
    "# Re-Fit Model\n",
    "######################\n",
    "\n",
    "epsilon = season_start_epsilon\n",
    "\n",
    "elo_dict = {}\n",
    "\n",
    "test_dict_list = []\n",
    "all_dict_list = []\n",
    "\n",
    "# For Each Game\n",
    "for i in range(games.shape[0]):\n",
    "\n",
    "    # Get Game Info\n",
    "    row = games.iloc[i]\n",
    "    team = row.team1\n",
    "    opp = row.team2\n",
    "    mov = row.score1 - row.score2\n",
    "\n",
    "    # Seasonal ELO Adjustment for Every Team\n",
    "    if i > 0 and row.season != games.iloc[i-1].season:\n",
    "        for k in elo_dict.keys():\n",
    "            elo_dict[k] = .75*elo_dict[k] + .25*1505\n",
    "\n",
    "        # Reset Epsilon\n",
    "        epsilon = season_start_epsilon\n",
    "\n",
    "    # If team's first game, use 538's elo to start\n",
    "    if team not in elo_dict.keys():\n",
    "        elo_dict[team] = row['elo1_pre']\n",
    "    if opp not in elo_dict.keys():\n",
    "        elo_dict[opp] = row['elo2_pre']\n",
    "\n",
    "    # Get Pre-Game ELO Estimates\n",
    "    team_pre = elo_dict[team]\n",
    "    opp_pre = elo_dict[opp]\n",
    "\n",
    "    # Adjust Epsilon Every 100 Games\n",
    "    if i % 100 == 0:\n",
    "        epsilon *= epsilon_decay\n",
    "\n",
    "    # Update ELOs based on game results    \n",
    "    elo_dict[team], elo_dict[opp] = get_post_elo(team, team_pre, opp, opp_pre, mov, epsilon)\n",
    "    \n",
    "    # Build DataFrame with new post-predictions\n",
    "    team_post = elo_dict[team]\n",
    "    opp_post = elo_dict[opp]\n",
    "\n",
    "    all_dict_list.append({'date': row.date, 'season': row.season,\n",
    "                          'team1': team, 'team2': opp, 'elo1_pre': team_pre, 'elo2_pre': opp_pre, 'elo1_post': team_post, 'elo2_post': opp_post,\n",
    "                          'elo1_pre_538': row['elo1_pre'], 'elo2_pre_538': row['elo2_pre'],\n",
    "                          'carm_elo1_pre_538': row['carm-elo1_pre'], 'carm_elo2_pre_538': row['carm-elo2_pre'],\n",
    "                          'carmelo1_pre_538': row['carmelo1_pre'], 'carmelo2_pre_538': row['carmelo2_pre'],\n",
    "                          'score1': row.score1, 'score2': row.score2,\n",
    "                          'MOV': mov})\n",
    "\n",
    "    # Final Model Testing\n",
    "    if row.season >= TEST_YEAR:\n",
    "\n",
    "        # Build DataFrame with new post-predictions\n",
    "        team_post = elo_dict[team]\n",
    "        opp_post = elo_dict[opp]\n",
    "\n",
    "        test_dict_list.append({'team1': team, 'team2': opp, 'team1_pre': team_pre, 'team2_pre': opp_pre, 'team1_post': team_post, 'team2_post': opp_post, 'MOV': mov})\n",
    "\n",
    "########################\n",
    "# Test DataFrame\n",
    "########################\n",
    "'''Get Results on Test Set for Final Comparison'''\n",
    "\n",
    "test_df= pd.DataFrame(test_dict_list)\n",
    "\n",
    "preds = []\n",
    "losses = []\n",
    "outcomes = []\n",
    "\n",
    "# For Each Game in Test Set\n",
    "for i in range(test_df.shape[0]):\n",
    "\n",
    "    # Get Game Info\n",
    "    row = test_df.iloc[i]\n",
    "    mov = row.MOV \n",
    "    team_elo = row['team1_pre']\n",
    "    opp_elo = row['team2_pre']\n",
    "\n",
    "    preds.append(get_win_prob(team_elo, opp_elo) > .5)\n",
    "    losses.append(np.log(get_win_prob(team_elo, opp_elo) if mov > 0 else 1 - get_win_prob(team_elo, opp_elo)))\n",
    "    outcomes.append(mov > 0)\n",
    "\n",
    "# True if Success, Otherwise False\n",
    "success_list = [preds[j] == outcomes[j] for j in range(len(preds))]\n",
    "\n",
    "# Print Classification Accuracy\n",
    "print('Loss of Chosen Model (on 2017 and 2018): ', np.sum(losses))\n",
    "print('Loss of Chosen Model (on 2017 and 2018): ', np.mean(success_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write New .csv w/ new ELOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(all_dict_list).to_csv('all_elos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Get This Year's Predictions (as well as CARMELO's)\n",
    "(Must be run directly after re-fitting)\n",
    "\n",
    "--------------------\n",
    "To update, just re-download .csv from fivethirtyeight's github and re-run everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get Just 2018-2019 Season Games\n",
    "games_2019 = data538[data538['season'] == 2019]\n",
    "games_2019 = games_2019[~np.isnan(games_2019['score1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adjust ELOs Back To Mean (For Change in Season)\n",
    "for k in elo_dict.keys():\n",
    "    elo_dict[k] = .75*elo_dict[k] + .25*1505\n",
    "\n",
    "# Reset Epsilon\n",
    "epsilon = season_start_epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "games_2019_dict_list = []\n",
    "\n",
    "# For Each Game in 2019\n",
    "for i in range(games_2019.shape[0]):\n",
    "\n",
    "    # Get Game Info\n",
    "    row = games.iloc[i]\n",
    "    team = row.team1\n",
    "    opp = row.team2\n",
    "    mov = row.score1 - row.score2\n",
    "    \n",
    "    # Get Pre-Game ELO Estimates\n",
    "    team_pre = elo_dict[team]\n",
    "    opp_pre = elo_dict[opp]\n",
    "\n",
    "    # Adjust Epsilon Every 100 Games\n",
    "    if i % 100 == 0:\n",
    "        epsilon *= epsilon_decay\n",
    "        \n",
    "    # Update ELOs based on game results    \n",
    "    elo_dict[team], elo_dict[opp] = get_post_elo(team, team_pre, opp, opp_pre, mov, epsilon)\n",
    "    \n",
    "    # Build DataFrame with new post-predictions\n",
    "    team_post = elo_dict[team]\n",
    "    opp_post = elo_dict[opp]\n",
    "\n",
    "    games_2019_dict_list.append({'date': row.date, 'season': row.season,\n",
    "                          'team1': team, 'team2': opp, 'elo1_pre': team_pre, 'elo2_pre': opp_pre, 'elo1_post': team_post, 'elo2_post': opp_post,\n",
    "                          'elo1_pre_538': row['elo1_pre'], 'elo2_pre_538': row['elo2_pre'],\n",
    "                          'carm_elo1_pre_538': row['carm-elo1_pre'], 'carm_elo2_pre_538': row['carm-elo2_pre'],\n",
    "                          'carmelo1_pre_538': row['carmelo1_pre'], 'carmelo2_pre_538': row['carmelo2_pre'],\n",
    "                          'score1': row.score1, 'score2': row.score2,\n",
    "                          'MOV': mov})\n",
    "    \n",
    "pd.DataFrame(games_2019_dict_list).to_csv('2019_elos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Fit Another Model, Further Tuning Shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_post_elo(home_team, home_team_elo, away_team, away_team_elo, mov, decay, home_adv):\n",
    "    \n",
    "    home_post_elo = get_k(mov, home_team_elo, away_team_elo, decay)*(int(mov>0) - get_win_prob(home_team_elo, away_team_elo, home_adv)) + home_team_elo\n",
    "    away_post_elo = away_team_elo + (home_team_elo - home_post_elo)\n",
    "    \n",
    "    return home_post_elo, away_post_elo\n",
    "    \n",
    "def get_win_prob(home_team_elo, away_team_elo, hfa):\n",
    "    home_team_elo += hfa\n",
    "    return 1.0/(1.0+(10.0**((away_team_elo-home_team_elo)/400)))\n",
    "\n",
    "def get_k(mov, team_elo, opp_elo, decay):\n",
    "    \n",
    "    if mov > 0: elo_dif = team_elo-opp_elo\n",
    "    else: elo_dif = opp_elo-team_elo\n",
    "    \n",
    "    K = 20.0*((np.abs(mov)+3.0)**.8)\n",
    "    K = K/(7.5 + .006*elo_dif)\n",
    "    return K*decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get Just Seasons 2010 and on\n",
    "games = data538[data538['season'] >= 2010]\n",
    "games = games[games['season'] < 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters to Tune\n",
    "season_start_epsilons = [.9, .95, .98, 1.0, 1.02, 1.05, 1.1, 1.15, 1.2, 1.3]\n",
    "epsilon_decays = [.8, .9, .925, .95, .97, .98, 1.0, 1.02, 1.05, 1.1, 1.2]\n",
    "hfas = [30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ejohn\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:85: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\ejohn\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: overflow encountered in double_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Accuracy:  -1550.25198981\n",
      "Best start_epsilon:  1.3\n",
      "Best epsilon_decay:  0.95\n",
      "Best epsilon_decay:  70.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ejohn\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Get Decay ELOs\n",
    "\n",
    "VALIDATE_YEAR = 2015\n",
    "TEST_YEAR = 2017\n",
    "\n",
    "val_results_dict_list = []\n",
    "test_results_dict_list = []\n",
    "\n",
    "# For Each Combination of start_epsilon and epsilon_decay\n",
    "for season_start_epsilon in season_start_epsilons:\n",
    "    for epsilon_decay in epsilon_decays:\n",
    "        for h in hfas:\n",
    "\n",
    "            epsilon = season_start_epsilon\n",
    "\n",
    "            elo_dict = {}\n",
    "\n",
    "            val_dict_list = []\n",
    "            test_dict_list = []\n",
    "\n",
    "            # For Each Game\n",
    "            for i in range(games.shape[0]):\n",
    "\n",
    "                # Get Game Info\n",
    "                row = games.iloc[i]\n",
    "                team = row.team1\n",
    "                opp = row.team2\n",
    "                mov = row.score1 - row.score2\n",
    "\n",
    "                # Seasonal ELO Adjustment for Every Team\n",
    "                if i > 0 and row.season != games.iloc[i-1].season:\n",
    "                    for k in elo_dict.keys():\n",
    "                        elo_dict[k] = .75*elo_dict[k] + .25*1505\n",
    "\n",
    "                    # Reset Epsilon\n",
    "                    epsilon = season_start_epsilon\n",
    "\n",
    "                # If team's first game, use 538's elo to start\n",
    "                if team not in elo_dict.keys():\n",
    "                    elo_dict[team] = row['elo1_pre']\n",
    "                if opp not in elo_dict.keys():\n",
    "                    elo_dict[opp] = row['elo2_pre']\n",
    "\n",
    "                # Get Pre-Game ELO Estimates\n",
    "                team_pre = elo_dict[team]\n",
    "                opp_pre = elo_dict[opp]\n",
    "\n",
    "                # Adjust Epsilon Every 100 Games\n",
    "                if i % 100 == 0:\n",
    "                    epsilon *= epsilon_decay\n",
    "\n",
    "                # Update ELOs based on game results    \n",
    "                elo_dict[team], elo_dict[opp] = get_post_elo(team, team_pre, opp, opp_pre, mov, epsilon, h)\n",
    "\n",
    "                # Model Validation\n",
    "                if row.season >= VALIDATE_YEAR and row.season < TEST_YEAR:\n",
    "\n",
    "                    # Build DataFrame with Post-Game ELOs\n",
    "                    team_post = elo_dict[team]\n",
    "                    opp_post = elo_dict[opp]\n",
    "                    val_dict_list.append({'team1': team, 'team2': opp, 'team1_pre': team_pre, 'team2_pre': opp_pre, 'team1_post': team_post, 'team2_post': opp_post, 'MOV': mov})\n",
    "\n",
    "            ########################\n",
    "            # Validation DataFrame\n",
    "            ########################\n",
    "            '''Choose the best model based on the validation set'''\n",
    "\n",
    "            val_df = pd.DataFrame(val_dict_list)\n",
    "\n",
    "            preds = []\n",
    "            losses = []\n",
    "            outcomes = []\n",
    "\n",
    "            # For Each Game in Validation Set\n",
    "            for i in range(val_df.shape[0]):\n",
    "\n",
    "                # Get Game Info\n",
    "                row = val_df.iloc[i]\n",
    "                mov = row.MOV \n",
    "                team_elo = row['team1_pre']\n",
    "                opp_elo = row['team2_pre']\n",
    "\n",
    "                # Get Predictions, Loss, and Results\n",
    "                preds.append(get_win_prob(team_elo, opp_elo, h) > .5)\n",
    "                losses.append(np.log(get_win_prob(team_elo, opp_elo, h) if mov > 0 else 1 - get_win_prob(team_elo, opp_elo, h)))\n",
    "                outcomes.append(mov > 0)\n",
    "\n",
    "            # True if Success, Otherwise False\n",
    "            #success_list = [preds[j] == outcomes[j] for j in range(len(preds))]\n",
    "\n",
    "            # Record Overall Loss\n",
    "\n",
    "\n",
    "            # Make DataFrame of Validation Results\n",
    "            #val_results_dict_list.append({'accuracy': np.mean(success_list), 'season_start_ep': season_start_epsilon, 'epsilon_decay': epsilon_decay})\n",
    "\n",
    "            # Make DataFrame of Validation Results w/ Loss as accuracy\n",
    "            val_results_dict_list.append({'accuracy': np.sum(losses), 'season_start_ep': season_start_epsilon, 'epsilon_decay': epsilon_decay, 'HFA': h})\n",
    "        \n",
    "val_results_df = pd.DataFrame(val_results_dict_list)\n",
    "\n",
    "print('Best Validation Accuracy: ', np.max(val_results_df['accuracy']))\n",
    "print('Best start_epsilon: ', val_results_df.loc[np.argmax(val_results_df['accuracy'])].season_start_ep)\n",
    "print('Best epsilon_decay: ', val_results_df.loc[np.argmax(val_results_df['accuracy'])].epsilon_decay)\n",
    "print('Best epsilon_decay: ', val_results_df.loc[np.argmax(val_results_df['accuracy'])].HFA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ejohn\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of Chosen Model (on 2017 and 2018):  -1625.47654702\n",
      "Accuracy of Chosen Model (on 2017 and 2018):  0.655475009538\n"
     ]
    }
   ],
   "source": [
    "# Re-Fit Model w/ Best Validation Results\n",
    "VALIDATE_YEAR = 2015\n",
    "TEST_YEAR = 2017\n",
    "\n",
    "test_results_dict_list = []\n",
    "\n",
    "# Get Hyperparameters from Validated Model\n",
    "season_start_epsilon = val_results_df.loc[np.argmax(val_results_df['accuracy'])].season_start_ep\n",
    "epsilon_decay = val_results_df.loc[np.argmax(val_results_df['accuracy'])].epsilon_decay\n",
    "hfa = val_results_df.loc[np.argmax(val_results_df['accuracy'])].HFA\n",
    "\n",
    "######################\n",
    "# Re-Fit Model\n",
    "######################\n",
    "\n",
    "epsilon = season_start_epsilon\n",
    "\n",
    "elo_dict = {}\n",
    "\n",
    "test_dict_list = []\n",
    "all_dict_list = []\n",
    "\n",
    "# For Each Game\n",
    "for i in range(games.shape[0]):\n",
    "\n",
    "    # Get Game Info\n",
    "    row = games.iloc[i]\n",
    "    team = row.team1\n",
    "    opp = row.team2\n",
    "    mov = row.score1 - row.score2\n",
    "\n",
    "    # Seasonal ELO Adjustment for Every Team\n",
    "    if i > 0 and row.season != games.iloc[i-1].season:\n",
    "        for k in elo_dict.keys():\n",
    "            elo_dict[k] = .75*elo_dict[k] + .25*1505\n",
    "\n",
    "        # Reset Epsilon\n",
    "        epsilon = season_start_epsilon\n",
    "\n",
    "    # If team's first game, use 538's elo to start\n",
    "    if team not in elo_dict.keys():\n",
    "        elo_dict[team] = row['elo1_pre']\n",
    "    if opp not in elo_dict.keys():\n",
    "        elo_dict[opp] = row['elo2_pre']\n",
    "\n",
    "    # Get Pre-Game ELO Estimates\n",
    "    team_pre = elo_dict[team]\n",
    "    opp_pre = elo_dict[opp]\n",
    "\n",
    "    # Adjust Epsilon Every 100 Games\n",
    "    if i % 100 == 0:\n",
    "        epsilon *= epsilon_decay\n",
    "\n",
    "    # Update ELOs based on game results    \n",
    "    elo_dict[team], elo_dict[opp] = get_post_elo(team, team_pre, opp, opp_pre, mov, epsilon, hfa)\n",
    "    \n",
    "    # Build DataFrame with new post-predictions\n",
    "    team_post = elo_dict[team]\n",
    "    opp_post = elo_dict[opp]\n",
    "\n",
    "    all_dict_list.append({'date': row.date, 'season': row.season,\n",
    "                          'team1': team, 'team2': opp, 'elo1_pre': team_pre, 'elo2_pre': opp_pre, 'elo1_post': team_post, 'elo2_post': opp_post,\n",
    "                          'elo1_pre_538': row['elo1_pre'], 'elo2_pre_538': row['elo2_pre'],\n",
    "                          'carm_elo1_pre_538': row['carm-elo1_pre'], 'carm_elo2_pre_538': row['carm-elo2_pre'],\n",
    "                          'carmelo1_pre_538': row['carmelo1_pre'], 'carmelo2_pre_538': row['carmelo2_pre'],\n",
    "                          'score1': row.score1, 'score2': row.score2,\n",
    "                          'MOV': mov})\n",
    "\n",
    "    # Final Model Testing\n",
    "    if row.season >= TEST_YEAR:\n",
    "\n",
    "        # Build DataFrame with new post-predictions\n",
    "        team_post = elo_dict[team]\n",
    "        opp_post = elo_dict[opp]\n",
    "\n",
    "        test_dict_list.append({'team1': team, 'team2': opp, 'team1_pre': team_pre, 'team2_pre': opp_pre, 'team1_post': team_post, 'team2_post': opp_post, 'MOV': mov})\n",
    "\n",
    "########################\n",
    "# Test DataFrame\n",
    "########################\n",
    "'''Get Results on Test Set for Final Comparison'''\n",
    "\n",
    "test_df= pd.DataFrame(test_dict_list)\n",
    "\n",
    "preds = []\n",
    "losses = []\n",
    "outcomes = []\n",
    "\n",
    "# For Each Game in Test Set\n",
    "for i in range(test_df.shape[0]):\n",
    "\n",
    "    # Get Game Info\n",
    "    row = test_df.iloc[i]\n",
    "    mov = row.MOV \n",
    "    team_elo = row['team1_pre']\n",
    "    opp_elo = row['team2_pre']\n",
    "\n",
    "    preds.append(get_win_prob(team_elo, opp_elo, hfa) > .5)\n",
    "    losses.append(np.log(get_win_prob(team_elo, opp_elo, hfa) if mov > 0 else 1 - get_win_prob(team_elo, opp_elo, hfa)))\n",
    "    outcomes.append(mov > 0)\n",
    "\n",
    "# True if Success, Otherwise False\n",
    "success_list = [preds[j] == outcomes[j] for j in range(len(preds))]\n",
    "\n",
    "# Print Classification Accuracy\n",
    "print('Loss of Chosen Model (on 2017 and 2018): ', np.sum(losses))\n",
    "print('Accuracy of Chosen Model (on 2017 and 2018): ', np.mean(success_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1430, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD8CAYAAACCRVh7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nshwSZmaW9f8BAQ5fF4ruwe8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(val_results_df['season_start_ep'], val_results_df['accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
